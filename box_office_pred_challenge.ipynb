{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB Box Office Prediction Project (Youssef Ben Fadhel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/kaggle/input/tmdb-box-office-prediction/\"\n",
    "train = pd.read_csv(path_data + 'train.csv')\n",
    "y = train[\"revenue\"]\n",
    "test = pd.read_csv(path_data + '/test.csv')\n",
    "test_ids = test[\"id\"]\n",
    "n_train = train.shape[0]\n",
    "n_test = test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rid of a few selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=[\"belongs_to_collection\",\"id\", \"imdb_id\", \"poster_path\", \"original_title\", \"title\", \"overview\"], inplace=True)\n",
    "test.drop(columns=[\"belongs_to_collection\", \"id\", \"imdb_id\", \"poster_path\", \"original_title\", \"title\", \"overview\"], inplace=True)\n",
    "print(train[\"status\"].value_counts())\n",
    "train.drop(columns=\"status\", inplace=True)\n",
    "test.drop(columns=\"status\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_NA = [100*train.isnull().sum()/n_test, 100*train.isnull().sum()/n_test]\n",
    "percentage_NA = pd.concat(percentage_NA, axis = 1, keys = [\"Missing in train (%)\",\n",
    "                                                 \"Missing in test (%)\"])\n",
    "print(percentage_NA[percentage_NA[\"Missing in train (%)\"] > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iszero_train = train[train==0]\n",
    "iszero_test = test[test==0]\n",
    "\n",
    "iszero_train.replace(0, 1, inplace=True)\n",
    "iszero_test.replace(0, 1, inplace=True)\n",
    "percentage_zero = [100*iszero_train.sum()/n_train, 100*iszero_test.sum()/n_test]\n",
    "percentage_zero = pd.concat(percentage_zero, axis = 1, keys = [\"Zero in train (%)\",\n",
    "                                                 \"Zero in test (%)\"])\n",
    "print(percentage_zero.loc[percentage_zero[\"Zero in train (%)\"] > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr()[\"revenue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 features with a significant number of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transforming incomplete data into binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"homepage\"].loc[~train[\"homepage\"].isnull()] = True\n",
    "train[\"homepage\"].loc[train[\"homepage\"].isnull()] = False\n",
    "train.rename(columns={'homepage':'has_homepage'}, inplace=True)\n",
    "fig = sns.catplot(x='has_homepage', y='revenue', hue = 'has_homepage', data=train)\n",
    "fig.savefig(\"homepage.png\")\n",
    "train['has_homepage'] = train['has_homepage'].astype('category').cat.codes\n",
    "\n",
    "test[\"homepage\"].loc[~test[\"homepage\"].isnull()] = True\n",
    "test[\"homepage\"].loc[test[\"homepage\"].isnull()] = False\n",
    "test.rename(columns={'homepage':'has_homepage'}, inplace=True)\n",
    "test['has_homepage'] = test['has_homepage'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"tagline\"].loc[~train[\"tagline\"].isnull()] = True\n",
    "train[\"tagline\"].loc[train[\"tagline\"].isnull()] = False\n",
    "train.rename(columns={'tagline':'has_tagline'}, inplace=True)\n",
    "fig = sns.catplot(x='has_tagline', y='revenue', hue = 'has_tagline', data=train)\n",
    "fig.savefig(\"tagline\")\n",
    "train['has_tagline'] =train['has_tagline'].astype('category').cat.codes\n",
    "\n",
    "test[\"tagline\"].loc[~test[\"tagline\"].isnull()] = True\n",
    "test[\"tagline\"].loc[test[\"tagline\"].isnull()] = False\n",
    "test.rename(columns={'tagline':'has_tagline'}, inplace=True)\n",
    "test['has_tagline'] = test['has_tagline'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputing missing values with a constant (the series' mean in this case) for variables with few missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"runtime\"].fillna(value=train[\"runtime\"].mean(), inplace=True)\n",
    "test[\"runtime\"].fillna(value=train[\"runtime\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For the features we'll create using the variables at hand, we'll fill the missing values this way as well after we construct them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We'll deal with the missing budget values after all variables are numerical (we'll see why)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train['original_language'], y=train['revenue'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"original_language\"].loc[~(train[\"original_language\"]==\"en\")] = 0\n",
    "train[\"original_language\"].loc[train[\"original_language\"]==\"en\"] = 1\n",
    "train.rename(columns={\"original_language\":\"en_original\"}, inplace=True)\n",
    "sns.catplot(x=\"en_original\", y=\"revenue\", data=train, hue=\"en_original\")\n",
    "\n",
    "test[\"original_language\"].loc[~(test[\"original_language\"]==\"en\")] = 0\n",
    "test[\"original_language\"].loc[test[\"original_language\"]==\"en\"] = 1\n",
    "test.rename(columns={\"original_language\":\"en_original\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"production_countries\"].fillna(method='bfill', inplace=True)\n",
    "train[\"production_countries\"] = [\n",
    "    ''.join(country_str.split(\"'name': '\")[1].split(\"'}\")[0]) for country_str in train[\"production_countries\"]]\n",
    "\n",
    "test[\"production_countries\"].fillna(method='bfill', inplace=True)\n",
    "test[\"production_countries\"] = [\n",
    "    ''.join(country_str.split(\"'name': '\")[1].split(\"'}\")[0]) for country_str in test[\"production_countries\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='production_countries', y='revenue', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"production_countries\"].loc[~(train[\"production_countries\"] == \"United States of America\")] = 0\n",
    "train[\"production_countries\"].loc[train[\"production_countries\"] == \"United States of America\"] = 1\n",
    "train.rename(columns={'production_countries':'is_prod_in_us'}, inplace=True)\n",
    "\n",
    "test[\"production_countries\"].loc[~(test[\"production_countries\"] == \"United States of America\")] = 0\n",
    "test[\"production_countries\"].loc[test[\"production_countries\"] == \"United States of America\"] = 1\n",
    "test.rename(columns={'production_countries':'is_prod_in_us'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"is_prod_in_us\", y=\"revenue\", data=train, hue=\"is_prod_in_us\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling non-numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The genre variable is more difficult as one movie can belong to several genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['genres'] = train['genres'].apply(lambda d: d if isinstance(d, str) else [])\n",
    "genres_list_train = [[''.join(s.split(\"'name': '\")[1].split(\"'\")[0]) for s in g.split(\"},\")]\n",
    "                if type(g)==str else [] for g in train[\"genres\"]]\n",
    "train[\"genres\"] = genres_list_train\n",
    "\n",
    "genres_list_test = [[''.join(s.split(\"'name': '\")[1].split(\"'\")[0]) for s in g.split(\"},\")]\n",
    "                if type(g)==str else [] for g in test[\"genres\"]]\n",
    "test[\"genres\"] = genres_list_test\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "d = mlb.fit_transform(train[\"genres\"])\n",
    "c = mlb.classes_\n",
    "cat_genres = pd.DataFrame(d, train.index, c)\n",
    "train = pd.concat([train, cat_genres], axis = 1)\n",
    "train.drop(columns=\"genres\", inplace=True)\n",
    "\n",
    "mlbt = MultiLabelBinarizer()\n",
    "d = mlbt.fit_transform(test[\"genres\"])\n",
    "c = mlbt.classes_\n",
    "cat_genres_t = pd.DataFrame(d, test.index, c)\n",
    "test = pd.concat([test, cat_genres_t], axis = 1)\n",
    "test.drop(columns=\"genres\", inplace=True)\n",
    "\n",
    "train.drop(columns=[\"TV Movie\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the release date into day/month/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['release_month', 'release_day', 'release_year']] = train['release_date'].str.split(\n",
    "    '/',expand=True).applymap(lambda x: int(x) if x!=np.NaN else x)\n",
    "test[['release_month', 'release_day', 'release_year']] = test['release_date'].str.split(\n",
    "    '/',expand=True).applymap(lambda x: int(x) if type(x)!=float else x)\n",
    "years = [1900+year if year>20 else 2000+year for year in train[\"release_year\"]]\n",
    "train[\"release_year\"] = years\n",
    "years = [1900+year if year>20 else 2000+year for year in test[\"release_year\"]]\n",
    "test[\"release_year\"] = years\n",
    "train.drop(['release_date'], axis=1, inplace=True)\n",
    "test.drop(['release_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"release_day\", y='revenue', data=train, hue=\"release_day\")\n",
    "plt.xticks([0,9,19,29])\n",
    "sns.catplot(x=\"release_month\", y='revenue', data=train, hue=\"release_month\")\n",
    "plt.figure()\n",
    "sns.scatterplot(x=\"release_year\", y='revenue', data=train, s=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting useful numerical info (crew_count, cast_count, keywords) from non-numerical variables counts (crew, cast, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(s):\n",
    "    try:\n",
    "        d = eval(s)\n",
    "    except:\n",
    "        d = {}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"cast\"].fillna(value=\"[]\", inplace=True)\n",
    "train[\"crew\"].fillna(value=\"[]\", inplace=True)\n",
    "train[\"Keywords\"].fillna(value=\"[]\", inplace=True)\n",
    "\n",
    "test[\"cast\"].fillna(value=\"[]\", inplace=True)\n",
    "test[\"crew\"].fillna(value=\"[]\", inplace=True)\n",
    "test[\"Keywords\"].fillna(value=\"[]\", inplace=True)\n",
    "\n",
    "train[\"cast\"] = [len(eval(c)) if len(eval(c))>0 else np.nan for c in train[\"cast\"]]\n",
    "train[\"crew\"] = [len(eval(c)) if len(eval(c))>0 else np.nan for c in train[\"crew\"]]\n",
    "train[\"Keywords\"] = [len(eval(c)) if len(eval(c))>0 else np.nan for c in train[\"Keywords\"]]\n",
    "\n",
    "test[\"cast\"] = [len(eval(c)) if len(eval(c))>0 else np.nan for c in test[\"cast\"]]\n",
    "test[\"crew\"] = [len(eval(c)) if len(eval(c))>0 else np.nan for c in test[\"crew\"]]\n",
    "test[\"Keywords\"] = [len(eval(c)) if len(eval(c))>0 else np.nan for c in test[\"Keywords\"]]\n",
    "\n",
    "train.rename(columns={'cast':'cast_count'}, inplace=True)\n",
    "train.rename(columns={'crew':'crew_count'}, inplace=True)\n",
    "train.rename(columns={'Keywords':'Keywords_count'}, inplace=True)\n",
    "\n",
    "test.rename(columns={'cast':'cast_count'}, inplace=True)\n",
    "test.rename(columns={'crew':'crew_count'}, inplace=True)\n",
    "test.rename(columns={'Keywords':'Keywords_count'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"cast_count\"].fillna(value=train[\"cast_count\"].mean(), inplace=True)\n",
    "train[\"crew_count\"].fillna(value=train[\"crew_count\"].mean(), inplace=True)\n",
    "train[\"Keywords_count\"].fillna(value=train[\"crew_count\"].mean(), inplace=True)\n",
    "\n",
    "test[\"cast_count\"].fillna(value=test[\"cast_count\"].mean(), inplace=True)\n",
    "test[\"crew_count\"].fillna(value=test[\"crew_count\"].mean(), inplace=True)\n",
    "test[\"Keywords_count\"].fillna(value=test[\"crew_count\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(x=\"cast_count\", y=\"revenue\",data=train, s=10)\n",
    "plt.figure()\n",
    "sns.scatterplot(x=\"crew_count\", y=\"revenue\",data=train, color='red',s=10)\n",
    "plt.figure()\n",
    "sns.scatterplot(x=\"Keywords_count\", y=\"revenue\",data=train[train[\"Keywords_count\"] < 30], s=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spoken languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(spoken_language):\n",
    "    try:\n",
    "        s = eval(spoken_language)\n",
    "    except:\n",
    "        s = {}\n",
    "    return s\n",
    "\n",
    "train[\"spoken_languages\"].fillna(value=\"[]\", inplace=True)\n",
    "test[\"spoken_languages\"].fillna(value=\"[]\", inplace=True)\n",
    "\n",
    "train[\"spoken_languages\"] = [({'iso_639_1': 'en', 'name': 'English'} in get_dict(l)) for l in train[\"spoken_languages\"]]\n",
    "test[\"spoken_languages\"] = [({'iso_639_1': 'en', 'name': 'English'} in get_dict(l)) for l in test[\"spoken_languages\"]]\n",
    "\n",
    "train[\"spoken_languages\"].loc[train[\"spoken_languages\"]==True] = 1\n",
    "train[\"spoken_languages\"].loc[train[\"spoken_languages\"]==False] = 0\n",
    "train.rename(columns={'spoken_languages':'is_en_spoken'}, inplace=True)\n",
    "\n",
    "test[\"spoken_languages\"].loc[test[\"spoken_languages\"]==True] = 1\n",
    "test[\"spoken_languages\"].loc[test[\"spoken_languages\"]==False] = 0\n",
    "test.rename(columns={'spoken_languages':'is_en_spoken'}, inplace=True)\n",
    "\n",
    "sns.catplot(x=\"is_en_spoken\", y=\"revenue\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"production_companies\"].fillna(value=\"[]\", inplace=True)\n",
    "train[\"production_companies\"] = [len(get_dict(c)) for c in train[\"production_companies\"]]\n",
    "train.rename(columns={'production_companies':'prod_companies_count'}, inplace=True)\n",
    "\n",
    "test[\"production_companies\"].fillna(value=\"[]\", inplace=True)\n",
    "test[\"production_companies\"] = [len(get_dict(c)) for c in test[\"production_companies\"]]\n",
    "test.rename(columns={'production_companies':'prod_companies_count'}, inplace=True)\n",
    "\n",
    "sns.catplot(x=\"prod_companies_count\", y=\"revenue\", data=train[train[\"prod_companies_count\"] != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with the budget missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"budget\"].loc[train[\"budget\"]==0] = np.NaN\n",
    "test[\"budget\"].loc[test[\"budget\"]==0] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer_train = KNNImputer(n_neighbors=5)\n",
    "imputer_test = KNNImputer(n_neighbors=5)\n",
    "scaler_train = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "train_norm = pd.DataFrame(scaler_train.fit_transform(train), columns = train.columns)\n",
    "test_norm = pd.DataFrame(scaler_test.fit_transform(test), columns = test.columns)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(20, 10), sharey=True)\n",
    "\n",
    "sns.histplot(ax=ax1[0], x=\"budget\", data=train_norm, kde=True, stat=\"probability\")\n",
    "sns.histplot(ax=ax2[0], x=\"budget\", data=test_norm, kde=True, stat=\"probability\")\n",
    "ax1[0].set_title(\"Histogram of budget in train ignoring missing values\")\n",
    "ax2[0].set_title(\"Histogram of budget in test ignoring missing values\")\n",
    "train_norm[\"budget\"].fillna(train_norm[\"budget\"].mean(), inplace=True)\n",
    "test_norm[\"budget\"].fillna(test_norm[\"budget\"].mean(), inplace=True)\n",
    "ax1[1].set_title(\"Histogram of budget in train with missing values set to budget mean\")\n",
    "ax2[1].set_title(\"Histogram of budget in test with missing values set to budget mean\")\n",
    "sns.histplot(ax=ax1[1], x=\"budget\", data=train_norm, kde=True, stat=\"probability\")\n",
    "sns.histplot(ax=ax2[1], x=\"budget\", data=test_norm, kde=True, stat=\"probability\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer_train = KNNImputer(n_neighbors=5)\n",
    "imputer_test = KNNImputer(n_neighbors=5)\n",
    "scaler_train = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "train_norm = pd.DataFrame(scaler_train.fit_transform(train), columns = train.columns)\n",
    "test_norm = pd.DataFrame(scaler_test.fit_transform(test), columns = test.columns)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(30, 10), sharey=True)\n",
    "\n",
    "sns.histplot(ax=ax1[0], x=\"budget\", data=train_norm, kde=True, stat=\"probability\")\n",
    "sns.histplot(ax=ax2[0], x=\"budget\", data=test_norm, kde=True, stat=\"probability\")\n",
    "ax1[0].set_title(\"Histogram of budget in train ignoring missing values\")\n",
    "ax2[0].set_title(\"Histogram of budget in test ignoring missing values\")\n",
    "\n",
    "train_norm = pd.DataFrame(imputer_train.fit_transform(train_norm),columns = train_norm.columns)\n",
    "test_norm = pd.DataFrame(imputer_test.fit_transform(test_norm),columns = test_norm.columns)\n",
    "\n",
    "sns.histplot(ax=ax1[1], x=\"budget\", data=train_norm, kde=True, stat=\"probability\")\n",
    "sns.histplot(ax=ax2[1], x=\"budget\", data=test_norm, kde=True, stat=\"probability\")\n",
    "ax1[1].set_title(\"Histogram of budget in train with KNN imputation\")\n",
    "ax2[1].set_title(\"Histogram of budget in test with KNN imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the training dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSLEknn = []\n",
    "accuracyknn = []\n",
    "for k in range(1, 20):\n",
    "    modelknn = KNeighborsRegressor(n_neighbors=k)\n",
    "    modelknn.fit(X_train,y_train)\n",
    "    y_pred=modelknn.predict(X_test)\n",
    "    accuracyknn.append((modelknn.score(X_test,y_test))*100)\n",
    "    RMSLEknn.append(math.sqrt(mean_squared_log_error(y_true=y_test,y_pred=y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = pd.read_csv(path_data + 'train.csv')\n",
    "X_simple = train_original[[\"budget\", \"runtime\"]]\n",
    "X_simple.fillna(0, inplace=True)\n",
    "X_simple_train, X_simple_test, y_train, y_test = train_test_split(X_simple, y, test_size=0.2, random_state=1)\n",
    "modelknn = KNeighborsRegressor()\n",
    "RMSLEknn = []\n",
    "accuracyknn = []\n",
    "\n",
    "for k in range(1, 20):\n",
    "    modelknn = KNeighborsRegressor(n_neighbors=k)\n",
    "    modelknn.fit(X_simple_train,y_train)\n",
    "    y_pred=modelknn.predict(X_simple_test)\n",
    "    accuracyknn.append((modelknn.score(X_simple_test,y_test))*100)\n",
    "    RMSLEknn.append(math.sqrt(mean_squared_log_error(y_true=y_test,y_pred=y_pred)))\n",
    "k_opt = np.array(RMSLEknn).argmin()+1\n",
    "\n",
    "RMSLE_forest = []\n",
    "accuracy_forest = []\n",
    "\n",
    "for n in [50,100,150,200,250]:\n",
    "    model_forest = RandomForestRegressor(n=n)\n",
    "    model_forest.fit(X_simple_train,y_train)\n",
    "    y_pred=model_forest.predict(X_simple_test)\n",
    "    accuracy_forest.append((model_forest.score(X_simple_test,y_test))*100)\n",
    "    RMSLE_forest.append(math.sqrt(mean_squared_log_error(y_true=y_test,y_pred=y_pred)))\n",
    "n_opt = 50*np.array(RMSLEknn).argmin()+1\n",
    "\n",
    "models=[LinearRegression(),RandomForestRegressor(),KNeighborsRegressor()]\n",
    "model_names=[\"LinearRegression\",\"RandomForestRegressor\",\"KNeighborsRegressor\",]\n",
    "accuracy = []\n",
    "RMSLE = []\n",
    "for model in range (len(models)):\n",
    "    model=models[model]\n",
    "    model.fit(X_simple_train,y_train)\n",
    "    y_pred=model.predict(X_simple_test)\n",
    "    y_pred[y_pred<0]=0\n",
    "    accuracy.append((model.score(X_simple_test,y_test))*100)\n",
    "    RMSLE.append(math.sqrt(mean_squared_log_error(y_true=y_test,y_pred=y_pred)))\n",
    "performances = pd.DataFrame({'Modelling Name':model_names,\"Accuracy\":accuracy,\"RMSLE\":RMSLE})\n",
    "print(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor()\n",
    "cv_results = cross_validate(model, X_train, y_train, cv=3, scoring=\"mean_scared_log_error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_norm.drop(\"revenue\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "models=[LinearRegression(),RandomForestRegressor(),KNeighborsRegressor()]\n",
    "model_names=[\"LinearRegression\",\"RandomForestRegressor\",\"KNeighborsRegressor\",]\n",
    "accuracy = []\n",
    "RMSLE = []\n",
    "for model in range (len(models)):\n",
    "    model=models[model]\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    y_pred[y_pred<0]=0\n",
    "    accuracy.append((model.score(X_test,y_test))*100)\n",
    "    RMSLE.append(math.sqrt(mean_squared_log_error(y_true=y_test,y_pred=y_pred)))\n",
    "performances = pd.DataFrame({'Modelling Name':model_names,\"Accuracy\":accuracy,\"RMSLE\":RMSLE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n=200)\n",
    "model.fit(X,y)\n",
    "Prediction = model.predict(test_norm)\n",
    "Predictions = pd.DataFrame({\"id\":test_ids,\"revenue\":Prediction})\n",
    "Predictions.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
